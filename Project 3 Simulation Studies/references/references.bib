
@article{rubin_inference_1976,
	title = {Inference and missing data},
	volume = {63},
	number = {3},
	journal = {Biometrika},
	author = {Rubin, Donald B},
	year = {1976},
	note = {Publisher: Oxford University Press},
	pages = {581--592},
}

@incollection{rubin_multiple_2018,
	title = {Multiple imputation},
	booktitle = {Flexible {Imputation} of {Missing} {Data}, {Second} {Edition}},
	publisher = {Chapman and Hall/CRC},
	author = {Rubin, Donald B},
	year = {2018},
	pages = {29--62},
}

@article{buuren_mice_2011,
	title = {mice: {Multivariate} {Imputation} by {Chained} {Equations} in {R}},
	volume = {45},
	doi = {10.18637/jss.v045.i03},
	number = {3},
	journal = {Journal of Statistical Software},
	author = {Buuren, Stef van and Groothuis-Oudshoorn, Karin},
	year = {2011},
	pages = {1--67},
}

@article{dagostino_general_2008,
	title = {General {Cardiovascular} {Risk} {Profile} for {Use} in {Primary} {Care}},
	volume = {117},
	url = {https://www.ahajournals.org/doi/full/10.1161/CIRCULATIONAHA.107.699579},
	doi = {10.1161/CIRCULATIONAHA.107.699579},
	abstract = {Background— Separate multivariable risk algorithms are commonly used to assess risk of specific atherosclerotic cardiovascular disease (CVD) events, ie, coronary heart disease, cerebrovascular disease, peripheral vascular disease, and heart failure. The present report presents a single multivariable risk function that predicts risk of developing all CVD and of its constituents.

Methods and Results— We used Cox proportional-hazards regression to evaluate the risk of developing a first CVD event in 8491 Framingham study participants (mean age, 49 years; 4522 women) who attended a routine examination between 30 and 74 years of age and were free of CVD. Sex-specific multivariable risk functions (“general CVD” algorithms) were derived that incorporated age, total and high-density lipoprotein cholesterol, systolic blood pressure, treatment for hypertension, smoking, and diabetes status. We assessed the performance of the general CVD algorithms for predicting individual CVD events (coronary heart disease, stroke, peripheral artery disease, or heart failure). Over 12 years of follow-up, 1174 participants (456 women) developed a first CVD event. All traditional risk factors evaluated predicted CVD risk (multivariable-adjusted P{\textless}0.0001). The general CVD algorithm demonstrated good discrimination (C statistic, 0.763 [men] and 0.793 [women]) and calibration. Simple adjustments to the general CVD risk algorithms allowed estimation of the risks of each CVD component. Two simple risk scores are presented, 1 based on all traditional risk factors and the other based on non–laboratory-based predictors.

Conclusions— A sex-specific multivariable risk factor algorithm can be conveniently used to assess general CVD risk and risk of individual CVD events (coronary, cerebrovascular, and peripheral arterial disease and heart failure). The estimated absolute CVD event rates can be used to quantify risk and to guide preventive care.},
	number = {6},
	urldate = {2023-12-03},
	journal = {Circulation},
	author = {D’Agostino, Ralph B. and Vasan, Ramachandran S. and Pencina, Michael J. and Wolf, Philip A. and Cobain, Mark and Massaro, Joseph M. and Kannel, William B.},
	month = feb,
	year = {2008},
	note = {Publisher: American Heart Association},
	keywords = {cardiovascular diseases, coronary disease, heart failure, risk factors, stroke},
	pages = {743--753},
	file = {Full Text PDF:/Users/shirleysong/Zotero/storage/X3GPMP7D/D’Agostino et al. - 2008 - General Cardiovascular Risk Profile for Use in Pri.pdf:application/pdf},
}

@misc{noauthor_framingham_2023,
	title = {Framingham {Heart} {Study}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Framingham_Heart_Study&oldid=1184051963},
	abstract = {The Framingham Heart Study is a long-term, ongoing cardiovascular cohort study of residents of the city of Framingham, Massachusetts. The study began in 1948 with 5,209 adult subjects from Framingham, and is now on its third generation of participants.  Prior to the study almost nothing was known about the epidemiology of hypertensive or arteriosclerotic cardiovascular disease. Much of the now-common knowledge concerning heart disease, such as the effects of diet, exercise, and common medications such as aspirin, is based on this longitudinal study. It is a project of the National Heart, Lung, and Blood Institute, in collaboration with (since 1971) Boston University.  Various health professionals from the hospitals and universities of Greater Boston staff the project.},
	language = {en},
	urldate = {2023-12-03},
	journal = {Wikipedia},
	month = nov,
	year = {2023},
	note = {Page Version ID: 1184051963},
	file = {Snapshot:/Users/shirleysong/Zotero/storage/55TBF3Y6/Framingham_Heart_Study.html:text/html},
}

@article{grembi_introducing_2022,
	title = {Introducing {riskCommunicator}: {An} {R} package to obtain interpretable effect estimates for public health},
	volume = {17},
	issn = {1932-6203},
	shorttitle = {Introducing {riskCommunicator}},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0265368},
	doi = {10.1371/journal.pone.0265368},
	abstract = {Common statistical modeling methods do not necessarily produce the most relevant or interpretable effect estimates to communicate risk. Overreliance on the odds ratio and relative effect measures limit the potential impact of epidemiologic and public health research. We created a straightforward R package, called riskCommunicator, to facilitate the presentation of a variety of effect measures, including risk differences and ratios, number needed to treat, incidence rate differences and ratios, and mean differences. The riskCommunicator package uses g-computation with parametric regression models and bootstrapping for confidence intervals to estimate effect measures in time-fixed data. We demonstrate the utility of the package using data from the Framingham Heart Study to estimate the effect of prevalent diabetes on the 24-year risk of cardiovascular disease or death. The package promotes the communication of public-health relevant effects and is accessible to a broad range of epidemiologists and health researchers with little to no expertise in causal inference methods or advanced coding.},
	language = {en},
	number = {7},
	urldate = {2023-12-03},
	journal = {PLOS ONE},
	author = {Grembi, Jessica A. and McQuade, Elizabeth T. Rogawski},
	month = jul,
	year = {2022},
	note = {Publisher: Public Library of Science},
	keywords = {Cardiovascular disease risk, Cardiovascular diseases, Diabetes mellitus, Epidemiology, Generalized linear model, Medical risk factors, Normal distribution, Public and occupational health},
	pages = {e0265368},
	file = {Full Text PDF:/Users/shirleysong/Zotero/storage/Y8TEHG94/Grembi and McQuade - 2022 - Introducing riskCommunicator An R package to obta.pdf:application/pdf},
}

@misc{noauthor_nhanes_2023,
	title = {{NHANES} - {About} the {National} {Health} and {Nutrition} {Examination} {Survey}},
	url = {https://www.cdc.gov/nchs/nhanes/about_nhanes.htm},
	language = {en-us},
	urldate = {2023-12-03},
	month = may,
	year = {2023},
	file = {Snapshot:/Users/shirleysong/Zotero/storage/UPUM3YQC/about_nhanes.html:text/html},
}

@misc{endres_nhanesa_2023,
	title = {{nhanesA}},
	url = {https://github.com/cjendres1/nhanes},
	abstract = {nhanesA: R package for browsing and retrieving NHANES data},
	urldate = {2023-12-03},
	author = {Endres, Christopher},
	month = nov,
	year = {2023},
	note = {original-date: 2015-04-14T18:25:53Z},
	keywords = {cran-r, nhanes},
}

@article{steingrimsson_transporting_2023,
	title = {Transporting a {Prediction} {Model} for {Use} in a {New} {Target} {Population}},
	volume = {192},
	issn = {0002-9262},
	url = {https://doi.org/10.1093/aje/kwac128},
	doi = {10.1093/aje/kwac128},
	abstract = {We considered methods for transporting a prediction model for use in a new target population, both when outcome and covariate data for model development are available from a source population that has a different covariate distribution compared with the target population and when covariate data (but not outcome data) are available from the target population. We discuss how to tailor the prediction model to account for differences in the data distribution between the source population and the target population. We also discuss how to assess the model’s performance (e.g., by estimating the mean squared prediction error) in the target population. We provide identifiability results for measures of model performance in the target population for a potentially misspecified prediction model under a sampling design where the source and the target population samples are obtained separately. We introduce the concept of prediction error modifiers that can be used to reason about tailoring measures of model performance to the target population. We illustrate the methods in simulated data and apply them to transport a prediction model for lung cancer diagnosis from the National Lung Screening Trial to the nationally representative target population of trial-eligible individuals in the National Health and Nutrition Examination Survey.},
	number = {2},
	urldate = {2023-12-03},
	journal = {American Journal of Epidemiology},
	author = {Steingrimsson, Jon A and Gatsonis, Constantine and Li, Bing and Dahabreh, Issa J},
	month = feb,
	year = {2023},
	pages = {296--304},
	file = {Snapshot:/Users/shirleysong/Zotero/storage/VEECDJMR/6648776.html:text/html;Submitted Version:/Users/shirleysong/Zotero/storage/FMK5VFTN/Steingrimsson et al. - 2023 - Transporting a Prediction Model for Use in a New T.pdf:application/pdf},
}

@article{morris_using_2019,
	title = {Using simulation studies to evaluate statistical methods},
	volume = {38},
	copyright = {© 2019 The Authors. Statistics in Medicine Published by John Wiley \& Sons Ltd.},
	issn = {1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8086},
	doi = {10.1002/sim.8086},
	abstract = {Simulation studies are computer experiments that involve creating data by pseudo-random sampling. A key strength of simulation studies is the ability to understand the behavior of statistical methods because some “truth” (usually some parameter/s of interest) is known from the process of generating the data. This allows us to consider properties of methods, such as bias. While widely used, simulation studies are often poorly designed, analyzed, and reported. This tutorial outlines the rationale for using simulation studies and offers guidance for design, execution, analysis, reporting, and presentation. In particular, this tutorial provides a structured approach for planning and reporting simulation studies, which involves defining aims, data-generating mechanisms, estimands, methods, and performance measures (“ADEMP”); coherent terminology for simulation studies; guidance on coding simulation studies; a critical discussion of key performance measures and their estimation; guidance on structuring tabular and graphical presentation of results; and new graphical presentations. With a view to describing recent practice, we review 100 articles taken from Volume 34 of Statistics in Medicine, which included at least one simulation study and identify areas for improvement.},
	language = {en},
	number = {11},
	urldate = {2023-12-03},
	journal = {Statistics in Medicine},
	author = {Morris, Tim P. and White, Ian R. and Crowther, Michael J.},
	year = {2019},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.8086},
	keywords = {graphics for simulation, Monte Carlo, simulation design, simulation reporting, simulation studies},
	pages = {2074--2102},
	file = {Full Text PDF:/Users/shirleysong/Zotero/storage/257FTKWL/Morris et al. - 2019 - Using simulation studies to evaluate statistical m.pdf:application/pdf;Snapshot:/Users/shirleysong/Zotero/storage/F8C8FCPS/sim.html:text/html},
}

@misc{paul_project_2023,
	title = {Project 3: {Simulation} {Studies}},
	url = {https://canvas.brown.edu/courses/1092384/assignments/7965587},
	urldate = {2023-12-04},
	author = {Paul, Alice},
	month = nov,
	year = {2023},
	file = {Project 3\: Simulation Studies:/Users/shirleysong/Zotero/storage/2X3HIG3E/7965587.html:text/html},
}

@misc{noauthor_log-normal_2023,
	title = {Log-normal distribution},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Log-normal_distribution&oldid=1188400077},
	abstract = {In probability theory, a log-normal (or lognormal) distribution is a continuous probability distribution of a random variable whose logarithm is normally distributed. Thus, if the random variable X is log-normally distributed, then  Y = ln(X)  has a normal distribution. Equivalently, if Y has a normal distribution, then the exponential function of Y,  X = exp(Y) , has a log-normal distribution. A random variable which is log-normally distributed takes only positive real values. It is a convenient and useful model for measurements in exact and engineering sciences, as well as medicine, economics and other topics (e.g., energies, concentrations, lengths, prices of financial instruments, and other metrics).
The distribution is occasionally referred to as the Galton distribution or Galton's distribution, after Francis Galton. The log-normal distribution has also been associated with other names, such as McAlister, Gibrat and Cobb–Douglas.A log-normal process is the statistical realization of the multiplicative product of many independent random variables, each of which is positive. This is justified by considering the central limit theorem in the log domain (sometimes called Gibrat's law). The log-normal distribution is the maximum entropy probability distribution for a random variate X—for which the mean and variance of ln(X) are specified.},
	language = {en},
	urldate = {2023-12-09},
	journal = {Wikipedia},
	month = dec,
	year = {2023},
	note = {Page Version ID: 1188400077},
	file = {Snapshot:/Users/shirleysong/Zotero/storage/EDSAJC5S/Log-normal_distribution.html:text/html},
}

@article{delignette-muller_fitdistrplus_2015,
	title = {fitdistrplus: {An} {R} {Package} for {Fitting} {Distributions}},
	volume = {64},
	url = {https://www.jstatsoft.org/index.php/jss/article/view/v064i04},
	doi = {10.18637/jss.v064.i04},
	abstract = {The package fitdistrplus provides functions for fitting univariate distributions to different types of data (continuous censored or non-censored data and discrete data) and allowing different estimation methods (maximum likelihood, moment matching, quantile matching and maximum goodness-of-fit estimation). Outputs of fitdist and fitdistcens functions are S3 objects, for which specific methods are provided, including summary, plot and quantile. This package also provides various functions to compare the fit of several distributions to the same data set and can handle to bootstrap parameter estimates. Detailed examples are given in food risk assessment, ecotoxicology and insurance contexts.},
	number = {4},
	journal = {Journal of Statistical Software},
	author = {Delignette-Muller, Marie Laure and Dutang, Christophe},
	year = {2015},
	pages = {1--34},
}
